library(tm)
library(tmcn)
library(Rwordseg)
library(Rwordseg)
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
getwd()
setwd("Rtextmining")
getwd()
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
d.corpus <- tm_map(d.corpus[1:100], segmentCN, nature = TRUE)
d.corpus <- tm_map(d.corpus, function(sentence) {
noun <- lapply(sentence, function(w) {
w[names(w) == "n"]
})
unlist(noun)
})
d.corpus <- Corpus(VectorSource(d.corpus))
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus[1:100], segmentCN, nature = TRUE)
d.corpus <- tm_map(d.corpus, function(sentence) {
noun <- lapply(sentence, function(w) {
w[names(w) == "n"]
})
unlist(noun)
})
d.corpus <- Corpus(VectorSource(d.corpus))
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, function(sentence) {
noun <- lapply(sentence, function(w) {
w[names(w) == "n"]
})
unlist(noun)
})
d.corpus <- Corpus(VectorSource(d.corpus))
d.corpus <- tm_map(d.corpus, removeWords, myStopWords)
head(myStopWords, 20)
myStopWords <- c(stopwordsCN(), "編輯", "時間", "標題", "發信", "實業", "作者")
d.corpus <- tm_map(d.corpus, removeWords, myStopWords)
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
inspect(tdm[1:10, 1:2])
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
inspect(tdm[1:10, 1:2])
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
d.corpus <- tm_map(d.corpus, removeWords, myStopWords)
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removeWords, myStopWords)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
d.corpus <- tm_map(d.corpus, removeWords, myStopWords)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removeWords, myStopWords)
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removeWords, myStopWords)
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus[1:100], segmentCN, nature = TRUE)
d.corpus <- tm_map(d.corpus, function(sentence) {
noun <- lapply(sentence, function(w) {
w[names(w) == "n"]
})
unlist(noun)
})
d.corpus <- Corpus(VectorSource(d.corpus))
d.corpus <- tm_map(d.corpus[1:100], segmentCN, nature = TRUE)
d
d.corpus
d.corpus <- tm_map(d.corpus, function(sentence) {
noun <- lapply(sentence, function(w) {
w[names(w) == "n"]
})
unlist(noun)
})
d.corpus <- Corpus(VectorSource(d.corpus))
d.corpus <- tm_map(d.corpus, removeWords, myStopWords)
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus[1:100], segmentCN, nature = TRUE)
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus[1:99], segmentCN, nature = TRUE)
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus[1:100], segmentCN, nature = TRUE)
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus[1:100], segmentCN, nature = TRUE)
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
words <- readLines("../tsaiword/TSAIWORD.TXT")
words <- toTrad(words)
insertWords(words)
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
words <- toTrad(words)
insertWords(words)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
words <- toTrad(words)
insertWords(words)
words <- readLines("../tsaiword/TSAIWORD.TXT")
words <- toTrad(words)
insertWords(words)
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
words <- readLines("../tsaiword/TSAIWORD.TXT")
words <- toTrad(words)
insertWords(words)
d.corpus <- tm_map(d.corpus[1:100], segmentCN, nature = TRUE)
d.corpus <- tm_map(d.corpus, function(sentence) {
noun <- lapply(sentence, function(w) {
w[names(w) == "n"]
})
unlist(noun)
})
d.corpus <- Corpus(VectorSource(d.corpus))
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
words <- readLines("../tsaiword/TSAIWORD.TXT")
words <- toTrad(words)
insertWords(words)
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
inspect(tdm[1:10, 1:2])
library(wordcloud)
m1 <- as.matrix(tdm)
v <- sort(rowSums(m1), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
wordcloud(d$word, d$freq, min.freq = 10, random.order = F, ordered.colors = F,
colors = rainbow(length(row.names(m1))))
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
d.corpus
d.corpus[1]
words <- readLines("../tsaiword/TSAIWORD.TXT")
words <- toTrad(words)
insertWords(words)
words <- readLines("../tsaiword/TSAIWORD.TXT")
insertWords(words)
words <- toTrad(words)
insertWords(words)
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
words <- readLines("../tsaiword/TSAIWORD.TXT")
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
words <- readLines("../tsaiword/TSAIWORD.TXT")
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
words <- readLines("../tsaiword/TSAIWORD.TXT")
words <- toTrad(words)
insertWords(words)
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
inspect(tdm[1:10, 1:2])
inspect(tdm[1:10, 1:20])
m1 <- as.matrix(tdm)
v <- sort(rowSums(m1), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
wordcloud(d$word, d$freq, min.freq = 10, random.order = F, ordered.colors = F,
colors = rainbow(length(row.names(m1))))
library(XML)
library(RCurl)
data <- list()
for( i in 1058:1118){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
data <- unlist(data)
sapply(data, getdoc)
getdoc <- function(line){
start <- regexpr('https://', line)[1]
end <- regexpr('html', line)[1]
if(start != -1 & end != -1){
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url), encoding='UTF-8')
doc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][6]
write(doc, gsub('html', 'txt', name))
}
}
sapply(data, getdoc)
library(tm)
library(tmcn)
library(Rwordseg)
d.corpus <- Corpus(DirSource(getwd()), list(language = NA))
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
words <- readLines("../tsaiword/TSAIWORD.TXT")
words <- toTrad(words)
insertWords(words)
d.corpus <- tm_map(d.corpus[1:100], segmentCN, nature = TRUE)
d.corpus <- tm_map(d.corpus, function(sentence) {
noun <- lapply(sentence, function(w) {
w[names(w) == "n"]
})
unlist(noun)
})
d.corpus <- Corpus(VectorSource(d.corpus))
myStopWords <- c(stopwordsCN(), "編輯", "時間", "標題", "發信", "實業", "作者", "批踢踢實業坊", "發信站", "From", "(ptt.cc)")
d.corpus <- tm_map(d.corpus, removeWords, myStopWords)
tdm <- TermDocumentMatrix(d.corpus, control = list(wordLengths = c(2, Inf)))
inspect(tdm[1:10, 1:2])
library(wordcloud)
m1 <- as.matrix(tdm)
v <- sort(rowSums(m1), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
wordcloud(d$word, d$freq, min.freq = 10, random.order = F, ordered.colors = F,
colors = rainbow(length(row.names(m1))))
m1 <- as.matrix(tdm)
v <- sort(rowSums(m1), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
wordcloud(d$word, d$freq, min.freq = 100, random.order = F, ordered.colors = F,
colors = rainbow(length(row.names(m1))))
